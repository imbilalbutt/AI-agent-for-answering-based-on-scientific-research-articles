{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-06T21:24:44.129689Z",
     "start_time": "2025-12-06T21:24:44.119996Z"
    }
   },
   "source": [
    "import os\n",
    "os.environ[\"LANGCHAIN_TELEMETRY\"] = \"false\"\n",
    "os.environ[\"CHROMA_TELEMETRY\"] = \"0\"\n",
    "os.environ[\"ANONYMIZED_TELEMETRY\"] = \"false\"\n",
    "\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "# from langchain.llms import huggingface_pipeline"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T21:25:50.353064Z",
     "start_time": "2025-12-06T21:24:45.308523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------\n",
    "# 1. Load PDF documents\n",
    "# ---------------------------\n",
    "docs_dir = \"docs\"\n",
    "pdf_files = [os.path.join(docs_dir, f) for f in os.listdir(docs_dir) if f.endswith(\".pdf\")][:10]\n",
    "\n",
    "documents = []\n",
    "for pdf_file in pdf_files:\n",
    "    loader = PyPDFLoader(pdf_file)\n",
    "    pages = loader.load_and_split()\n",
    "    documents.extend(pages)\n",
    "\n",
    "print(f\"Loaded {len(documents)} pages from {len(pdf_files)} PDFs.\")\n"
   ],
   "id": "6510a96de82df18a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 297 pages from 10 PDFs.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T21:29:00.801666Z",
     "start_time": "2025-12-06T21:29:00.690286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "chunks = text_splitter.split_documents(documents)"
   ],
   "id": "a322ec6ba0e53b13",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T21:29:10.000552Z",
     "start_time": "2025-12-06T21:29:07.636378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------\n",
    "# 2. Create embeddings (Hugging Face)\n",
    "# ---------------------------\n",
    "embedding_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_model_name)\n"
   ],
   "id": "9be5aef89dabb378",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T21:31:07.553249Z",
     "start_time": "2025-12-06T21:29:44.300870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------\n",
    "# 3. Store embeddings in Chroma\n",
    "# ---------------------------\n",
    "from langchain_chroma import Chroma\n",
    "vector_db_dir = \"./chroma_db4\"\n",
    "if not os.path.exists(vector_db_dir):\n",
    "    os.makedirs(vector_db_dir)\n",
    "\n",
    "db = Chroma.from_documents(chunks, embeddings, persist_directory=vector_db_dir)\n",
    "print(\"Embeddings stored in Chroma vector database.\")\n",
    "\n"
   ],
   "id": "780b2b82249f9d1d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings stored in Chroma vector database.\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T21:31:19.661513Z",
     "start_time": "2025-12-06T21:31:19.654154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------\n",
    "# 4. Create LangChain retriever\n",
    "# ---------------------------\n",
    "retriever = db.as_retriever()\n"
   ],
   "id": "51f09350e02a90e4",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T21:31:23.258634Z",
     "start_time": "2025-12-06T21:31:21.481352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------\n",
    "# 5. Create Hugging Face LLM\n",
    "# ---------------------------\n",
    "# Text generation pipeline (can use \"hkunlp/instructor-large\" or similar)\n",
    "from transformers import pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "# from langchain_huggingface import HuggingFacePipeline\n",
    "hf_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"google/flan-t5-small\",\n",
    "    max_length=512\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=hf_pipeline)"
   ],
   "id": "ad04383c114f011b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "The model 'T5ForConditionalGeneration' is not supported for text-generation. Supported models are ['PeftModelForCausalLM', 'ApertusForCausalLM', 'ArceeForCausalLM', 'AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BitNetForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'BltForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DeepseekV2ForCausalLM', 'DeepseekV3ForCausalLM', 'DiffLlamaForCausalLM', 'DogeForCausalLM', 'Dots1ForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'Ernie4_5ForCausalLM', 'Ernie4_5_MoeForCausalLM', 'Exaone4ForCausalLM', 'FalconForCausalLM', 'FalconH1ForCausalLM', 'FalconMambaForCausalLM', 'FlexOlmoForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'Gemma3nForConditionalGeneration', 'Gemma3nForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'Glm4ForCausalLM', 'Glm4MoeForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GptOssForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeHybridForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'HunYuanDenseV1ForCausalLM', 'HunYuanMoEV1ForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'Lfm2ForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'Llama4ForCausalLM', 'LongcatFlashForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MiniMaxForCausalLM', 'MinistralForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'ModernBertDecoderForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'Olmo3ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'Phi4MultimodalForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'Qwen3NextForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'SeedOssForCausalLM', 'SmolLM3ForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'VaultGemmaForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'xLSTMForCausalLM', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T21:31:25.640271Z",
     "start_time": "2025-12-06T21:31:25.534141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------\n",
    "# 6. Create RetrievalQA chain\n",
    "# ---------------------------\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever\n",
    ")\n"
   ],
   "id": "8f95a1bee5111f06",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T21:31:40.602582Z",
     "start_time": "2025-12-06T21:31:28.769016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------\n",
    "# 7. Ask questions interactively\n",
    "# ---------------------------\n",
    "while True:\n",
    "    query = input(\"\\nEnter your question (or 'exit' to quit): \")\n",
    "    if query.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    answer = qa_chain.invoke({\"query\": query})\n",
    "    print(\"\\nAnswer (LangChain RAG):\")\n",
    "    print(answer[\"result\"])\n"
   ],
   "id": "1132775f260e793a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1179 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer (LangChain RAG):\n",
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "101 9 Maschinelles Lernen  zur Bestimmung von  up  \n",
      "Dieses Kapitel beschreibt, wie es mÃ¶glich ist, Verfahren des maschinellen Lernens zu nutzen, \n",
      "um den Algorithmus ğ‘¢ğ‘ anhand kleine r Menge n gelabelte r Beispiele zu lernen.  \n",
      "Entsprechend seiner Anforderungen (siehe Abschnitt 7.9) muss ğ‘¢ğ‘ deterministisch die \n",
      "unbekannte Variablenabstraktion  ğ›¼ğ‘¢ğ‘ nachbilden. Da ğ›¼ğ‘¢ğ‘ definitionsgemÃ¤ÃŸ (siehe Abschnitt \n",
      "7.4) eine surjektive Abbildung ist, handelt es sich bei der Bestimmung von ğ‘¢ğ‘ um ein \n",
      "Regressionsproblem.  \n",
      "Zur LÃ¶sung derartiger  Problem e gibt es eine Reihe von etablierten Verfahren.  Die ausgewÃ¤hlter  \n",
      "Verfahren zur Bestimmung von ğ‘¢ğ‘ wurde bereits betrachtet  (Wittek, 2018) . Hierzu wurden \n",
      "unter Anderem  vier Trainingsmengen mit jeweils 20 Datenpunkten ausgewÃ¤hlt . Als \n",
      "Abstraktionsfunktion wurden dabei Summe, Mittelwert und Median sowie die Projektion auf \n",
      "eine Komponente genutzt. Ausgewertet wurde der mean squared error. Die beste n Ergebnisse \n",
      "aller Verfahren  waren fÃ¼r:\n",
      "\n",
      "different technical languages. While the LLMs can be trained to synthesise a variety di fferent\n",
      "kinds of data as inputs, it can also be used to take a set of results of recommendations and\n",
      "output these in di fferent technical languages. For example, the electrical, mechanical, and\n",
      "materials teams for the design of a smart sensor network may all have di fferent reporting\n",
      "and documentation requirements and need di fferent levels of detail and replicability. Using\n",
      "the same set of design outputs, recommendations, design candidates, and data evaluations, a\n",
      "properly-trained LLM could generate di fferent technical reports and documentation in these\n",
      "different technical languages.\n",
      "â€¢Generation of reports and automated documentation : Related to the previous point, an\n",
      "LLM could be used in parallel with the design team and stakeholders to automatically gen-\n",
      "erate progress reports and technical documentation. These documents could be kept updated\n",
      "\n",
      "arXiv Template A P REPRINT\n",
      "\" cant_angle \": ANGLE_IN_DEGREES ,\n",
      "\" material \": \" MATERIAL \",\n",
      "\" thickness \": THICKNESS_IN_METERS ,\n",
      "},\n",
      "\" tail \": {\n",
      "\" length \": LENGTH_IN_METERS ,\n",
      "\" top_radius \": RADIUS_IN_METERS ,\n",
      "\" bottom_radius \": RADIUS_IN_METERS ,\n",
      "\" material \": \" MATERIAL \",\n",
      "},\n",
      "},\n",
      "\" parachutes \": {\n",
      "\" main \": {\n",
      "\" name \": \" Main \",\n",
      "\" cd_s \": AREA ,\n",
      "\" trigger \": \" apogee \",\n",
      "\" sampling_rate \": 105 ,\n",
      "\"lag \": 1.5 ,\n",
      "\" noise \": (0, 8.3 , 0.5) ,\n",
      "},\n",
      "\" drogue \": {\n",
      "\" name \": \" Drogue \",\n",
      "\" cd_s \": AREA ,\n",
      "\" trigger \": \" apogee \",\n",
      "\" sampling_rate \": 105 ,\n",
      "\"lag \": 1.5 ,\n",
      "\" noise \": (0, 8.3 , 0.5) ,\n",
      "},\n",
      "},\n",
      "\" launch \": {\n",
      "\" rail_length \": LENGTH_IN_METERS ,\n",
      "\" inclination \": ANGLE_IN_DEGREES , #90 is vertical launch\n",
      "\" heading \": ANGLE_IN_DEGREES , # Heading in degrees 0 is up\n",
      "},\n",
      "\" payload \": { # point mass as position specified\n",
      "\" mass \": MASS_IN_KG ,\n",
      "\" position \": POSITION_IN_METERS , # relative to rocket center\n",
      "},\n",
      "}\n",
      "â€˜â€˜â€˜\n",
      "Here â€™s an example valid design . This is not at all indicative of what you should\n",
      "\n",
      "durch das Netz reprÃ¤sentierten Verteilung zu produzieren, um diese Verteilung zu schÃ¤tzen, \n",
      "weiterhin bestehen.  \n",
      "10.1.5  Zusammenfassung  \n",
      "MDN und KMN mit Noise -Regularisierung und Normalisierung haben sich in der L iteratur als \n",
      "gut geeignet herausgestellt , um bedingte Wahrscheinlichkeiten zu modellieren (Ambrogioni, \n",
      "2017; Bishop, 2013; Rothfuss, 2019) . Es ist zu erwarten, dass sie auch bei der Bestimmung von \n",
      "ğ‘‘ğ‘œğ‘¤ğ‘›  gute Ergebnisse liefern. NKDE sind in Benchmarks im direkten Vergleich den beiden \n",
      "auf neuronalen Netzen basierten Verfahren unterlegen (Rothfuss, 2019) . \n",
      "SFNN konnten bei multimodaler Regression fÃ¼r einige der Testsets bessere log -Likelihood \n",
      "Werte erreichen (Tang, 2013) . Allerdings sind diese Werte dennoch insgesamt mit denen von \n",
      "MDN vergleichbar. Durch die Monte -Carlo -Simulation ist das Lernverfahren von SFNN bei \n",
      "gleicher Epochen zahl im  Vergleich  zu MDN mindestens  mit dem Faktor des\n",
      "\n",
      "Question: what is weather\n",
      "Helpful Answer:\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "168b6fe4bc734502"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
